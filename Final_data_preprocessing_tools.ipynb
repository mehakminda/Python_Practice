{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mehakminda/Python_Practice/blob/main/Final_data_preprocessing_tools.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37puETfgRzzg"
      },
      "source": [
        "# Data Preprocessing Tools"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EoRP98MpR-qj"
      },
      "source": [
        "## Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "V_w3ujzecNLR"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RopL7tUZSQkT"
      },
      "source": [
        "## Importing the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Identifying the features and dependent variable entities,\n",
        "we predict the value of dependent variable based on the feature/independent variable.\n",
        "\n",
        "\n",
        "iloc[:]/iloc[:,:] :  All rows and all columns\n",
        "iloc[0] : first row, all column\n",
        "iloc[1:4] : from row 1 to row 3, all coulmn\n",
        "iloc[:, :2] : all rows, columns at index 0,1\n",
        "iloc[:,:-1] : locate indexes .. all row, all column except last one\n",
        "iloc[:,:-2] : locate indexes .. all row, all column except the last 2\n",
        "iloc[:,-1] : all rows, only last column\n",
        "\n",
        ": -> range\n",
        "-1 -> last column\n",
        "2:-1 -> from 2 to excluding the last column\n"
      ],
      "metadata": {
        "id": "hnzG8rIdhaQ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#read the dataset from file using pandas and store it in a variable\n",
        "dataset= pd.read_csv(\"Data.csv\")\n",
        "\n",
        "#locate the values index wise from the dataset\n",
        "X= dataset.iloc[:,:-1].values\n",
        "Y= dataset.iloc[:,-1].values"
      ],
      "metadata": {
        "id": "pkQ2guLaeNTK"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cI6y6vRTtjFP",
        "outputId": "87200bcc-d446-419f-9f24-a91a064fe8ca"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['France' 44.0 72000.0]\n",
            " ['Spain' 27.0 48000.0]\n",
            " ['Germany' 30.0 54000.0]\n",
            " ['Spain' 38.0 61000.0]\n",
            " ['Germany' 40.0 nan]\n",
            " ['France' 35.0 58000.0]\n",
            " ['Spain' nan 52000.0]\n",
            " ['France' 48.0 79000.0]\n",
            " ['Germany' 50.0 83000.0]\n",
            " ['France' 37.0 67000.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqrJE1OPtjk1",
        "outputId": "4cfa6e80-d5b9-4fbf-fa82-2823ecb5123a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['No' 'Yes' 'No' 'No' 'Yes' 'Yes' 'No' 'Yes' 'No' 'Yes']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhfKXNxlSabC"
      },
      "source": [
        "## Taking care of missing data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Either delete the missing data if there is huge datset\n",
        "2. Handle it properly by replacing it with some value based on some strategy\n",
        "(mean/media/most occured value/some specified constant)\n",
        "\n",
        "scikit-learn -> simpleImputer -> fill/replaces missing data\n",
        "import the SimpleImputer class from the sklearn.impute module in scikit-learn, a popular machine learning library in Python.\n",
        "\n",
        "Fit method: evaluates the mean value and identifies the places where there is missing value,\n",
        "Transform: replaces the missing value with average"
      ],
      "metadata": {
        "id": "pHfirA3SKJ_q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "#Instance of class 'SimpleImputer'\n",
        "#SimpleImputer(which values to replace, with what values to replace)\n",
        "imputer = SimpleImputer(missing_values=np.nan,strategy='mean')\n",
        "\n",
        "#Connect/Apply this Imputer to our matrix/datset\n",
        "\n",
        "# the attribute in fit method, should only have numeric values not text or categorical data, hence we removed country column\n",
        "imputer.fit(X[:,1:3])\n",
        "\n",
        "#transform method - same atrribute as fit\n",
        "#tranform method will now returns the matrix X with new replaced values\n",
        "X[:,1:3]=imputer.transform(X[:,1:3])\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "o3gLaf5JuC13"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "psA73EyYYZRm",
        "outputId": "af1d4ff3-37c2-43e8-dd5c-2670f0bbdbf4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['France' 44.0 72000.0]\n",
            " ['Spain' 27.0 48000.0]\n",
            " ['Germany' 30.0 54000.0]\n",
            " ['Spain' 38.0 61000.0]\n",
            " ['Germany' 40.0 63777.77777777778]\n",
            " ['France' 35.0 58000.0]\n",
            " ['Spain' 38.77777777777778 52000.0]\n",
            " ['France' 48.0 79000.0]\n",
            " ['Germany' 50.0 83000.0]\n",
            " ['France' 37.0 67000.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CriG6VzVSjcK"
      },
      "source": [
        "## Encoding categorical data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhSpdQWeSsFh"
      },
      "source": [
        "### Encoding the Independent Variable"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Country column : france, spain, germany..this   is a categorical data\n",
        "\n",
        "ColumnTransformer: allows you to apply different preprocessing steps to different columns of your dataset, especially when the data is a mix of nuerical and categorical data.\n",
        "lets you define a pipeline that applies:\n",
        "\n",
        "1. Imputation to numerical columns\n",
        "2. Encoding to categorical columns\n",
        "3. Scaling to selected columns ...all in one go\n",
        "\n",
        "StandardScaler:It standardizes numerical features by removing the mean and scaling to unit variance.\n",
        "\n",
        "OneHotEncoder: It converts categorical variables into a format that can be provided to ML algorithms.\n",
        "Convert them into numbers using 'OneHotEncoding'\n",
        "OneHotEncoding: creates binary vector\n",
        "France:[1,0,0]\n",
        "spain:[0,1,0]\n",
        "Germany:[0,0,1]\n"
      ],
      "metadata": {
        "id": "erIXxusdgx_L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#is used to import the ColumnTransformer class from sklearn.compose in scikit-learn.\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "#create an object/instance of ColumnTransformer class\n",
        "#One hot encoding creates binary vector, (ie) get get binary data for the categorical values\n",
        "#create vector of size to the number of values .. there it is three(spain, france, germany)\n",
        "#transfor[(kind of tranformation, what kind of transforamtion, on what columns)]\n",
        "ct=ColumnTransformer(transformers=[('encoder',OneHotEncoder(),[0])], remainder='passthrough')\n",
        "\n",
        "#Connect with Matrix Feature X\n",
        "# output of fit_Transform is not a numpy array, but fror our future machine learning steps of traning set we want X as numpy array , hence we convert the output of fit_transform into numpy array\n",
        "X=np.array(ct.fit_transform(X))\n",
        "\n",
        "#in output we get tuple for each country value\n",
        "\n"
      ],
      "metadata": {
        "id": "MWb69mDKhBME"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h38rUqZcipCb",
        "outputId": "e3832c0b-62e0-4f77-c749-0dc1fe969f73"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.0 0.0 0.0 44.0 72000.0]\n",
            " [0.0 0.0 1.0 27.0 48000.0]\n",
            " [0.0 1.0 0.0 30.0 54000.0]\n",
            " [0.0 0.0 1.0 38.0 61000.0]\n",
            " [0.0 1.0 0.0 40.0 63777.77777777778]\n",
            " [1.0 0.0 0.0 35.0 58000.0]\n",
            " [0.0 0.0 1.0 38.77777777777778 52000.0]\n",
            " [1.0 0.0 0.0 48.0 79000.0]\n",
            " [0.0 1.0 0.0 50.0 83000.0]\n",
            " [1.0 0.0 0.0 37.0 67000.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXh8oVSITIc6"
      },
      "source": [
        "### Encoding the Dependent Variable"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LabelEncoder is used to convert categorical labels (strings) into numeric values.(but only if the categories have an ordinal relationship[link text]"
      ],
      "metadata": {
        "id": "FvU_WM1Pzhl6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "#create an instance of LabelEncoder (only 2 values-> 0,1-> yes, No)\n",
        "le = LabelEncoder()\n",
        "\n",
        "#link labelencoder with Y\n",
        "# we need not convert this into numpy array, as its the dependent variable, it need not be a numpy array\n",
        "Y=le.fit_transform(Y)\n"
      ],
      "metadata": {
        "id": "jY2D10Zlzevj"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fo1e7k0zg1L",
        "outputId": "39c89d8f-4b71-4d65-96e3-fa6a60138ff0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 0 0 1 1 0 1 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Should we apply feature scaling before after splitting dataset into training set ad test set\n",
        "\n",
        "Test set should be like a new set to evaluate our model's accuracy\n",
        "apply feature scaling on test set is like information leakage that is knowing the customer data in production prehand, with this the results might not be accurate."
      ],
      "metadata": {
        "id": "8DwZ0TLb2a0F"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qb_vcgm3qZKW"
      },
      "source": [
        "## Splitting the dataset into the Training set and Test set"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "#matrix feature of training set\n",
        "#matrix feature of test set\n",
        "#matrix of dependent variable of trainig set\n",
        "#matrix of dependent variable of test set\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=1 )\n"
      ],
      "metadata": {
        "id": "kMJyxvzx1Tdi"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icnj47Zc1TaE",
        "outputId": "71261697-084c-4438-993a-a25655035fbe"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.0 0.0 1.0 38.77777777777778 52000.0]\n",
            " [0.0 1.0 0.0 40.0 63777.77777777778]\n",
            " [1.0 0.0 0.0 44.0 72000.0]\n",
            " [0.0 0.0 1.0 38.0 61000.0]\n",
            " [0.0 0.0 1.0 27.0 48000.0]\n",
            " [1.0 0.0 0.0 48.0 79000.0]\n",
            " [0.0 1.0 0.0 50.0 83000.0]\n",
            " [1.0 0.0 0.0 35.0 58000.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQ8XUbrX1TXH",
        "outputId": "6be6c512-2d5d-4b14-f8d0-2d4a28933ac7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.0 1.0 0.0 30.0 54000.0]\n",
            " [1.0 0.0 0.0 37.0 67000.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(Y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11d2a8Wd1TUI",
        "outputId": "2e1c3aa0-7efb-48b7-d3f4-c4e29908ca96"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 0 0 1 1 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_yvT7xy6dtX",
        "outputId": "90bad486-1035-4dfa-dd98-977048473314"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpGqbS4TqkIR"
      },
      "source": [
        "## Feature Scaling"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Why, so that some features do not dominate the other features, because if this happens undominated features can be ignored by machine learning models.\n",
        "\n",
        "1. Normalization : (x-min(x)/max(x)-min(x)) and the output values lies in the range [0,1]\n",
        "- applied when the features is normally distributed.\n",
        "2. Standardization: (x-mean(x)/standard deviation(x)) and the output values lies in range [-3,3]\n",
        "- works all the time\n",
        "\n",
        "Purpose is all the values are in same scale/between a certain range\n",
        "\n",
        "\n",
        "Do we have to apply the feature scaling to the dummy variables in features (ie the values generated after one hot encoding )\n",
        "NO, standardization means to have all the values in same range[-3,3].\n",
        "Dummy variables already lie between [-3,3], so even if you apply it would make any different\n"
      ],
      "metadata": {
        "id": "zObLlpwtvCUJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train[:,3:] = sc.fit_transform(X_train[:,3:])\n",
        "X_test[:,3:] = sc.fit_transform(X_test[:,3:])\n",
        "#fit : will getthe mean and standard deviation\n",
        "#transform will actualy apply the formula for each of the value\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "We-vY5ZtvB-J"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ol2LNg324DU3",
        "outputId": "5e87dc74-e9d0-4932-f5ac-4864749c80ed"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.0 0.0 1.0 -0.19159184384578545 -1.0781259408412425]\n",
            " [0.0 1.0 0.0 -0.014117293757057777 -0.07013167641635372]\n",
            " [1.0 0.0 0.0 0.566708506533324 0.633562432710455]\n",
            " [0.0 0.0 1.0 -0.30453019390224867 -0.30786617274297867]\n",
            " [0.0 0.0 1.0 -1.9018011447007988 -1.420463615551582]\n",
            " [1.0 0.0 0.0 1.1475343068237058 1.232653363453549]\n",
            " [0.0 1.0 0.0 1.4379472069688968 1.5749910381638885]\n",
            " [1.0 0.0 0.0 -0.7401495441200351 -0.5646194287757332]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3y8EuM_f4HKx",
        "outputId": "06137efe-aed8-4aaa-9834-90f79e9c18bc"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.0 1.0 0.0 -1.0 -1.0]\n",
            " [1.0 0.0 0.0 1.0 1.0]]\n"
          ]
        }
      ]
    }
  ]
}